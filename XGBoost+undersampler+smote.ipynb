{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3f124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bfe317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672867d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.529912</td>\n",
       "      <td>0.873892</td>\n",
       "      <td>1.347247</td>\n",
       "      <td>0.145457</td>\n",
       "      <td>0.414209</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.711206</td>\n",
       "      <td>0.176066</td>\n",
       "      <td>-0.286717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046949</td>\n",
       "      <td>0.208105</td>\n",
       "      <td>-0.185548</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.098816</td>\n",
       "      <td>-0.552904</td>\n",
       "      <td>-0.073288</td>\n",
       "      <td>0.023307</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.535388</td>\n",
       "      <td>0.865268</td>\n",
       "      <td>1.351076</td>\n",
       "      <td>0.147575</td>\n",
       "      <td>0.433680</td>\n",
       "      <td>0.086983</td>\n",
       "      <td>0.693039</td>\n",
       "      <td>0.179742</td>\n",
       "      <td>-0.285642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049526</td>\n",
       "      <td>0.206537</td>\n",
       "      <td>-0.187108</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.098117</td>\n",
       "      <td>-0.553471</td>\n",
       "      <td>-0.078306</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282987</th>\n",
       "      <td>171288.0</td>\n",
       "      <td>1.912550</td>\n",
       "      <td>-0.455240</td>\n",
       "      <td>-1.750654</td>\n",
       "      <td>0.454324</td>\n",
       "      <td>2.089130</td>\n",
       "      <td>4.160019</td>\n",
       "      <td>-0.881302</td>\n",
       "      <td>1.081750</td>\n",
       "      <td>1.022928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524067</td>\n",
       "      <td>-1.337510</td>\n",
       "      <td>0.473943</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>-0.283548</td>\n",
       "      <td>-1.084843</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>-0.036020</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283483</th>\n",
       "      <td>171627.0</td>\n",
       "      <td>-1.464380</td>\n",
       "      <td>1.368119</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>-0.601282</td>\n",
       "      <td>-0.689115</td>\n",
       "      <td>-0.487154</td>\n",
       "      <td>-0.303778</td>\n",
       "      <td>0.884953</td>\n",
       "      <td>0.054065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287217</td>\n",
       "      <td>0.947825</td>\n",
       "      <td>-0.218773</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>0.044127</td>\n",
       "      <td>0.639270</td>\n",
       "      <td>0.213565</td>\n",
       "      <td>0.119251</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283485</th>\n",
       "      <td>171627.0</td>\n",
       "      <td>-1.457978</td>\n",
       "      <td>1.378203</td>\n",
       "      <td>0.811515</td>\n",
       "      <td>-0.603760</td>\n",
       "      <td>-0.711883</td>\n",
       "      <td>-0.471672</td>\n",
       "      <td>-0.282535</td>\n",
       "      <td>0.880654</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284205</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>-0.216949</td>\n",
       "      <td>0.083250</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.639933</td>\n",
       "      <td>0.219432</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284191</th>\n",
       "      <td>172233.0</td>\n",
       "      <td>-2.667936</td>\n",
       "      <td>3.160505</td>\n",
       "      <td>-3.355984</td>\n",
       "      <td>1.007845</td>\n",
       "      <td>-0.377397</td>\n",
       "      <td>-0.109730</td>\n",
       "      <td>-0.667233</td>\n",
       "      <td>2.309700</td>\n",
       "      <td>-1.639306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391483</td>\n",
       "      <td>0.266536</td>\n",
       "      <td>-0.079853</td>\n",
       "      <td>-0.096395</td>\n",
       "      <td>0.086719</td>\n",
       "      <td>-0.451128</td>\n",
       "      <td>-1.183743</td>\n",
       "      <td>-0.222200</td>\n",
       "      <td>55.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284193</th>\n",
       "      <td>172233.0</td>\n",
       "      <td>-2.691642</td>\n",
       "      <td>3.123168</td>\n",
       "      <td>-3.339407</td>\n",
       "      <td>1.017018</td>\n",
       "      <td>-0.293095</td>\n",
       "      <td>-0.167054</td>\n",
       "      <td>-0.745886</td>\n",
       "      <td>2.325616</td>\n",
       "      <td>-1.634651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402639</td>\n",
       "      <td>0.259746</td>\n",
       "      <td>-0.086606</td>\n",
       "      <td>-0.097597</td>\n",
       "      <td>0.083693</td>\n",
       "      <td>-0.453584</td>\n",
       "      <td>-1.205466</td>\n",
       "      <td>-0.213020</td>\n",
       "      <td>36.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "33          26.0 -0.529912  0.873892  1.347247  0.145457  0.414209  0.100223   \n",
       "35          26.0 -0.535388  0.865268  1.351076  0.147575  0.433680  0.086983   \n",
       "113         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "114         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "115         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "282987  171288.0  1.912550 -0.455240 -1.750654  0.454324  2.089130  4.160019   \n",
       "283483  171627.0 -1.464380  1.368119  0.815992 -0.601282 -0.689115 -0.487154   \n",
       "283485  171627.0 -1.457978  1.378203  0.811515 -0.603760 -0.711883 -0.471672   \n",
       "284191  172233.0 -2.667936  3.160505 -3.355984  1.007845 -0.377397 -0.109730   \n",
       "284193  172233.0 -2.691642  3.123168 -3.339407  1.017018 -0.293095 -0.167054   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "33      0.711206  0.176066 -0.286717  ...  0.046949  0.208105 -0.185548   \n",
       "35      0.693039  0.179742 -0.285642  ...  0.049526  0.206537 -0.187108   \n",
       "113    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "114    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "115    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "282987 -0.881302  1.081750  1.022928  ... -0.524067 -1.337510  0.473943   \n",
       "283483 -0.303778  0.884953  0.054065  ...  0.287217  0.947825 -0.218773   \n",
       "283485 -0.282535  0.880654  0.052808  ...  0.284205  0.949659 -0.216949   \n",
       "284191 -0.667233  2.309700 -1.639306  ...  0.391483  0.266536 -0.079853   \n",
       "284193 -0.745886  2.325616 -1.634651  ...  0.402639  0.259746 -0.086606   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "33      0.001031  0.098816 -0.552904 -0.073288  0.023307    6.14      0  \n",
       "35      0.000753  0.098117 -0.553471 -0.078306  0.025427    1.77      0  \n",
       "113    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "114    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "115    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "282987  0.616683 -0.283548 -1.084843  0.073133 -0.036020   11.99      0  \n",
       "283483  0.082926  0.044127  0.639270  0.213565  0.119251    6.82      0  \n",
       "283485  0.083250  0.044944  0.639933  0.219432  0.116772   11.93      0  \n",
       "284191 -0.096395  0.086719 -0.451128 -1.183743 -0.222200   55.66      0  \n",
       "284193 -0.097597  0.083693 -0.453584 -1.205466 -0.213020   36.74      0  \n",
       "\n",
       "[1081 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated = df.duplicated() \n",
    "df_duplicated = df[duplicated]\n",
    "df_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a049f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2203ef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after drop duplicated, how many Fraud left: 473\n"
     ]
    }
   ],
   "source": [
    "Fraud = df[df['Class'] == 1].shape[0]\n",
    "print('after drop duplicated, how many Fraud left:',Fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd32bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 建立 StandardScaler 實例\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "y = df['Class']\n",
    "x = df.drop('Class', axis=1)\n",
    "x = pd.DataFrame(std_scaler.fit_transform(x), columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d73b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4730, 1: 946})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "\n",
    "steps = [('under', under),('over', over)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "x_resampled, y_resampled = pipeline.fit_resample(x, y)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d47370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4540\n",
      "Test set size: 1136\n",
      "Training set Fraud: 757\n",
      "Testing set Fraud: 189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 將數據集拆分為訓練集和測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, shuffle=True , stratify=y_resampled, random_state=42)\n",
    "\n",
    "# 打印拆分後的訓練集和測試集大小\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))\n",
    "print(\"Training set Fraud:\", sum(y_train == 1))\n",
    "print(\"Testing set Fraud:\", sum(y_test == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031372ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:16:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:16:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:17:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:17:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 創建 XGBoost 分類器\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# 進行訓練\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "# 進行交叉驗證，並計算分數\n",
    "cv_scores = cross_val_score(xgb, x_train, y_train, cv=5)  # 這裡的cv可以改變交叉驗證的折數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514d0683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.97356828 0.97797357 0.98678414 0.98568282 0.97907489]\n",
      "Mean CV Score: 0.9806167400881058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       947\n",
      "           1       0.98      0.93      0.96       189\n",
      "\n",
      "    accuracy                           0.99      1136\n",
      "   macro avg       0.98      0.96      0.97      1136\n",
      "weighted avg       0.99      0.99      0.99      1136\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 輸出交叉驗證的分數\n",
    "print(\"Cross Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", cv_scores.mean())\n",
    "\n",
    "# 產生分類報告\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n",
    "print('\\n')\n",
    "\n",
    "# 產生混淆矩陣\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
